#!/usr/bin/env python3
"""
è¯¦ç»†çš„Ollamaè¯Šæ–­è„šæœ¬
"""

import requests
import json
import sys
import subprocess
import time

def run_command(cmd):
    """è¿è¡Œå‘½ä»¤è¡Œå‘½ä»¤"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.returncode, result.stdout, result.stderr
    except Exception as e:
        return -1, "", str(e)

def diagnose_ollama():
    """è¯Šæ–­OllamaæœåŠ¡"""
    print("ğŸ” å¼€å§‹è¯Šæ–­OllamaæœåŠ¡...")
    
    # 1. æ£€æŸ¥Ollamaè¿›ç¨‹
    print("\n1. æ£€æŸ¥Ollamaè¿›ç¨‹...")
    if sys.platform == "win32":
        returncode, stdout, stderr = run_command("tasklist | findstr ollama")
    else:
        returncode, stdout, stderr = run_command("ps aux | grep ollama")
    
    if returncode == 0 and "ollama" in stdout:
        print("âœ… Ollamaè¿›ç¨‹æ­£åœ¨è¿è¡Œ")
    else:
        print("âŒ Ollamaè¿›ç¨‹æœªè¿è¡Œ")
        print("ğŸ’¡ è¯·è¿è¡Œ: ollama serve")
        return False
    
    # 2. æ£€æŸ¥APIè¿æ¥
    print("\n2. æ£€æŸ¥APIè¿æ¥...")
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=10)
        if response.status_code == 200:
            print("âœ… APIè¿æ¥æ­£å¸¸")
            models = response.json()
            if 'models' in models and models['models']:
                print("ğŸ“š å¯ç”¨æ¨¡å‹:")
                for model in models['models']:
                    print(f"   - {model['name']} (å¤§å°: {model.get('size', 'æœªçŸ¥')})")
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
        else:
            print(f"âŒ APIè¿”å›é”™è¯¯: {response.status_code}")
            print(f"   å“åº”: {response.text}")
    except Exception as e:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {e}")
        return False
    
    # 3. æ£€æŸ¥ç‰¹å®šæ¨¡å‹
    print("\n3. æ£€æŸ¥llama3.1æ¨¡å‹...")
    try:
        # æµ‹è¯•æ¨¡å‹ç”Ÿæˆ
        test_payload = {
            "model": "llama3.1",
            "prompt": "è¯·å›å¤'OK'è¡¨ç¤ºä½ å·¥ä½œæ­£å¸¸ã€‚",
            "stream": False
        }
        response = requests.post(
            "http://localhost:11434/api/generate",
            json=test_payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ: {result.get('response', 'æ— å“åº”')}")
            return True
        else:
            print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯: {response.text}")
            
            # å°è¯•æ‹‰å–æ¨¡å‹
            print("\nğŸ”„ å°è¯•æ‹‰å–llama3.1æ¨¡å‹...")
            returncode, stdout, stderr = run_command("ollama pull llama3.1")
            if returncode == 0:
                print("âœ… æ¨¡å‹æ‹‰å–æˆåŠŸï¼Œè¯·é‡æ–°æµ‹è¯•")
                # ç­‰å¾…æ¨¡å‹åŠ è½½
                time.sleep(5)
                return diagnose_ollama()  # é‡æ–°è¯Šæ–­
            else:
                print("âŒ æ¨¡å‹æ‹‰å–å¤±è´¥")
                print(f"   é”™è¯¯: {stderr}")
                return False
                
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = diagnose_ollama()
    if success:
        print("\nğŸ‰ Ollamaè¯Šæ–­å®Œæˆï¼ŒæœåŠ¡æ­£å¸¸ï¼")
        sys.exit(0)
    else:
        print("\nğŸ’¥ Ollamaè¯Šæ–­å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè§£å†³é—®é¢˜ã€‚")
        sys.exit(1)